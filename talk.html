<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>LOZEEì™€ ëŒ€í™”í•˜ê¸°</title>
  <link rel="stylesheet" href="style.css" />
  <link href="https://fonts.googleapis.com/css2?family=KoPub+World+Dotum:wght@400;700&display=swap" rel="stylesheet" />
</head>
<body>
  <header id="main-header">LOZEEì™€ ëŒ€í™”í•˜ê¸°</header>
  <div id="meter-container"><div id="volume-meter"><div id="volume-level"></div></div></div>
  <div id="chat-container"></div>

  <div id="chat-input-container">
    <button id="mic-button" title="ìŒì„± ì¸ì‹ ì‹œìž‘/ì¤‘ì§€">ðŸŽ¤</button>
    <input type="text" id="chat-input" placeholder="ë©”ì‹œì§€ë¥¼ ìž…ë ¥í•˜ê±°ë‚˜ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”..." />
    <button id="send-button">ì „ì†¡</button>
  </div>

  <script type="module">
    // ê²½ë¡œ ìˆ˜ì •: js/counseling_topics.js
    import { topicsByAge } from './js/counseling_topics.js';
    import { playTTSFromText, DEFAULT_VOICE } from './js/tts.js';
    import { getGptResponse, getFirstQuestion } from './js/gpt-dialog.js';
    import { trackTime, trackEmotionTone, trackSituation } from './js/basic-features.js';

    document.addEventListener('DOMContentLoaded', () => {
      console.log('DOM loaded, initializing chat');
      const chatContainer = document.getElementById('chat-container');
      const chatInput     = document.getElementById('chat-input');
      const sendButton    = document.getElementById('send-button');
      const micButton     = document.getElementById('mic-button');
      const meterLevel    = document.getElementById('volume-level');

      const selectedVoice = localStorage.getItem('lozee_selectedVoice') || DEFAULT_VOICE;
      const userAge       = localStorage.getItem('lozee_userage');
      const userName      = localStorage.getItem('lozee_username') || 'ì¹œêµ¬';
      let selectedTopic   = JSON.parse(localStorage.getItem('selectedTopic') || '{}');

      let recognitionActive = false;
      let stt;

      function appendBubble(text, role) {
        console.log('appendBubble', role, text);
        const el = document.createElement('div');
        el.className = `bubble ${role}`;
        el.textContent = text;
        chatContainer.appendChild(el);
        chatContainer.scrollTop = chatContainer.scrollHeight;
      }

      function showAiLoading(show) {
        sendButton.disabled = show;
        chatInput.disabled  = show;
        micButton.disabled  = show;
      }

      function resolveTopicDetail() {
        const a = parseInt(userAge, 10);
        let ageKey;
        if (a >= 8 && a <= 10) ageKey = '8-10';
        else if (a >= 11 && a <= 15) ageKey = '11-15';
        else ageKey = '30+';

        const data = topicsByAge[ageKey] || {};
        if (selectedTopic.category && data[selectedTopic.category]) return selectedTopic;
        const firstCat = Object.keys(data)[0];
        const firstTopic = data[firstCat]?.[0] || { displayText: 'ëŒ€í™”', icon: 'ðŸ’¬' };
        selectedTopic = firstTopic;
        return selectedTopic;
      }

      async function initConversation() {
        console.log('initConversation');
        const topic = resolveTopicDetail();
        const firstQ = getFirstQuestion(userAge, topic);
        appendBubble(firstQ, 'bot');
        await playTTSFromText(firstQ, selectedVoice);
        trackTime();
        trackEmotionTone();
        trackSituation();
      }

      async function handleUserText(text) {
        console.log('handleUserText:', text);
        if (!text.trim()) return;
        appendBubble(text, 'user');
        showAiLoading(true);

        const botBubble = document.createElement('div');
        botBubble.className = 'bubble bot';
        chatContainer.appendChild(botBubble);
        chatContainer.scrollTop = chatContainer.scrollHeight;

        try {
          const res = await fetch('/api/gpt-stream', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ userInput: text, context: { userAge, userName, selectedTopic } })
          });
          const reader = res.body.getReader();
          const dec = new TextDecoder();
          let done = false;
          while (!done) {
            const { value, done: d } = await reader.read();
            done = d;
            botBubble.textContent += dec.decode(value, { stream: true });
            chatContainer.scrollTop = chatContainer.scrollHeight;
          }
          await playTTSFromText(botBubble.textContent, selectedVoice);
        } catch (err) {
          console.error('GPT error', err);
          appendBubble('ì£„ì†¡í•´ìš”, ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.', 'bot');
          await playTTSFromText('ì£„ì†¡í•´ìš”, ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.', selectedVoice);
        } finally {
          showAiLoading(false);
        }
      }

      sendButton.addEventListener('click', () => {
        const txt = chatInput.value.trim();
        if (txt) { chatInput.value = ''; handleUserText(txt); }
      });
      chatInput.addEventListener('keydown', e => {
        if (e.key === 'Enter' && !sendButton.disabled) handleUserText(chatInput.value.trim());
      });

      if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
        const API = window.SpeechRecognition || window.webkitSpeechRecognition;
        stt = new API();
        stt.lang = 'ko-KR'; stt.interimResults = false;
        stt.onstart  = () => { recognitionActive = true; micButton.textContent = 'ðŸ”´'; };
        stt.onend    = () => { recognitionActive = false; micButton.textContent = 'ðŸŽ¤'; };
        stt.onresult = e => { handleUserText(e.results[0][0].transcript); };
        micButton.onclick = () => recognitionActive ? stt.stop() : stt.start();
      }

      initConversation();
    });
  </script>
</body>
</html>
```
