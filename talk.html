<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LOZEE와 대화하기</title>
  <link rel="stylesheet" href="style.css">
  <link href="https://fonts.googleapis.com/css2?family=KoPub+World+Dotum:wght@400;700&display=swap" rel="stylesheet">
  <style>
    body { margin:0; padding:0; font-family:'KoPub World Dotum',sans-serif; display:flex; flex-direction:column; height:100vh; background:#fff; color:#333; }
    #main-header { background:#0095FF; color:#fff; padding:1rem; text-align:center; font-size:1.25rem; flex-shrink:0; }
    #meter-container { display:flex; align-items:center; justify-content:center; padding:0.5rem 0; background:#f4f4f4; flex-shrink:0; }
    #volume-meter { width:80%; height:8px; border:1px solid #ccc; border-radius:4px; overflow:hidden; }
    #volume-level { height:100%; background:#0095FF; width:0; transition:width 0.1s ease; }
    #chat-container { flex:1; overflow-y:auto; padding:1rem; display:flex; flex-direction:column; gap:0.75rem; }
    .bubble { max-width:80%; padding:0.75rem 1rem; border-radius:1rem; line-height:1.5; white-space:pre-wrap; }
    .user { background:#fff9c4; align-self:flex-end; border-bottom-right-radius:0.25rem; }
    .ai { background:#0095FF; color:#fff; align-self:flex-start; border-bottom-left-radius:0.25rem; }
  </style>
</head>
<body>
  <header id="main-header">LOZEE와 대화하기</header>
  <div id="meter-container"><div id="volume-meter"><div id="volume-level"></div></div></div>
  <div id="chat-container"></div>

  <script type="module">
    import { playTTSFromText, AVAILABLE_VOICES, DEFAULT_VOICE } from './js/tts.js';
    import { getGptResponse, getInitialGreeting } from './js/gpt-dialog.js';
    import { getSTTFromAudio } from './js/stt.js';

    const chatContainer = document.getElementById('chat-container');
    const meterLevel = document.getElementById('volume-level');

    // 음성 옵션은 tts.js에서 관리
    const selectedVoice = localStorage.getItem('lozee_selectedVoice') || DEFAULT_VOICE;

    function appendMessage(content, role) {
      const el = document.createElement('div');
      el.className = `bubble ${role}`;
      el.textContent = typeof content === 'string' ? content : (content.text || JSON.stringify(content));
      chatContainer.appendChild(el);
      chatContainer.scrollTop = chatContainer.scrollHeight;
    }

    async function initConversation() {
      const userName = localStorage.getItem('lozee_username') || '친구';
      const greeting = await getInitialGreeting(userName);
      appendMessage(greeting, 'ai');
      await playTTSFromText(greeting, selectedVoice);
    }

    function initVAD() {
      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
          const audioCtx = new AudioContext();
          const source = audioCtx.createMediaStreamSource(stream);
          const analyser = audioCtx.createAnalyser(); analyser.fftSize = 2048;
          source.connect(analyser);
          const dataArr = new Uint8Array(analyser.fftSize);

          let recording = false, recorder = null, chunks = [];
          let silenceFrames = 0, speakFrames = 0;
          const MIN_SPEAK_FRAMES = 5, MIN_SILENCE_FRAMES = 15;

          function analyze() {
            analyser.getByteTimeDomainData(dataArr);
            let sum = 0;
            dataArr.forEach(v => sum += Math.pow(v/128 - 1, 2));
            const vol = Math.sqrt(sum / dataArr.length);
            meterLevel.style.width = `${Math.min(vol * 200, 100)}%`;

            if (vol > 0.05) { speakFrames++; silenceFrames = 0; }
            else { silenceFrames++; }

            if (!recording && speakFrames >= MIN_SPEAK_FRAMES) {
              recording = true; chunks = []; speakFrames = 0;
              recorder = new MediaRecorder(stream);
              recorder.ondataavailable = e => chunks.push(e.data);
              recorder.start();
            }
            if (recording && silenceFrames >= MIN_SILENCE_FRAMES) {
              recorder.onstop = async () => {
                const blob = new Blob(chunks, { type: chunks[0]?.type });
                try {
                  const sttText = await getSTTFromAudio(blob);
                  appendMessage(sttText, 'user');
                  const aiText = await getGptResponse(sttText);
                  appendMessage(aiText, 'ai');
                  await playTTSFromText(aiText, selectedVoice);
                } catch (err) {
                  console.error(err);
                }
              };
              recording = false; silenceFrames = 0;
              recorder.stop();
            }

            requestAnimationFrame(analyze);
          }
          analyze();
        })
        .catch(console.error);
    }

    initConversation();
    initVAD();
  </script>
</body>
</html>
