<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LOZEE ìƒë‹´</title>
  <link rel="stylesheet" href="style.css">
  <style>
    body { display:flex; flex-direction:column; height:100vh; margin:0; font-family:'KoPubWorld Dotum',sans-serif; }
    #main-header { background:#0095FF; color:#fff; padding:1rem; text-align:center; font-size:1.25rem; }
    #mic-indicator { text-align:center; padding:0.5rem; font-size:0.9rem; background:#eef; }
    #chat-window { flex:1; overflow-y:auto; padding:1rem; display:flex; flex-direction:column; gap:0.75rem; }
    .bubble { max-width:80%; padding:0.75rem 1rem; border-radius:1rem; line-height:1.4; white-space:pre-wrap; }
    .user { background:#fff9c4; color:#333; align-self:flex-end; border-bottom-right-radius:0.25rem; }
    .ai   { background:#0095FF;  color:#fff; align-self:flex-start; border-bottom-left-radius:0.25rem; }
    #silence-banner { text-align:center; padding:0.5rem; background:#f0f0f0; color:#666; font-size:0.9rem; display:none; }
    #loading-indicator { display:none; text-align:center; padding:0.5rem; color:#555; font-style:italic; }
  </style>
</head>
<body>
  <header id="main-header">LOZEE ìƒë‹´</header>
  <div id="mic-indicator">ğŸ”µ ëŒ€ê¸° ì¤‘</div>
  <div id="chat-window"></div>
  <div id="silence-banner">ë§ì”€í•˜ì‹œë©´ ë°”ë¡œ ë“¤ì–´ë“œë ¤ìš”</div>
  <div id="loading-indicator">ì²˜ë¦¬ ì¤‘...</div>

<script type="module">
import { playTTSFromText } from './js/tts.js';
import { getGptResponse } from './js/gpt-dialog.js';

// ìƒíƒœ ë¨¸ì‹ 
const State = { READY:'READY', RECORD:'RECORD', SILENCE:'SILENCE', PROCESS:'PROCESS' };
let currentState = State.READY, silenceTimer;
const chatWindow = document.getElementById('chat-window');
const micIndicator= document.getElementById('mic-indicator');
const banner     = document.getElementById('silence-banner');
const loading    = document.getElementById('loading-indicator');

// TTS ì„¤ì •
const ttsVoice = localStorage.getItem('lozee_tts_voice') || 'ko-KR-Chirp3-HD-Vindemiatrix';

function appendMessage(text, role) {
  const div = document.createElement('div'); div.className = `bubble ${role}`; div.textContent = text;
  chatWindow.appendChild(div); chatWindow.scrollTop = chatWindow.scrollHeight;
  return div;
}
function showBanner(on) { banner.style.display = on ? 'block':'none'; }
function showLoading(on){ loading.style.display = on? 'block':'none'; }
function setMicStatus(text){ micIndicator.textContent = text; }
function transition(to){ clearTimeout(silenceTimer); currentState = to; showBanner(to === State.SILENCE); console.log('State â†’', to); }

async function handleUserTurn(text, systemPrompt=''){
  appendMessage(text, 'user'); showLoading(true);
  const res = await getGptResponse(text, systemPrompt);
  const aiText = typeof res==='string' ? res : (res.error || res.rephrasing || 'ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.');
  appendMessage(aiText, 'ai');
  await playTTSFromText(aiText, ttsVoice);
  showLoading(false);
}

// STT ì¤€ë¹„: getUserMedia ê¶Œí•œ ìš”ì²­ & VAD, SpeechRecognition ì„¤ì •
let recognition, userBubble;
(async()=>{
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    transition(State.READY);
    // AudioWorklet VAD
    const ctx = new AudioContext();
    await ctx.audioWorklet.addModule('vad-processor.js');
    const src = ctx.createMediaStreamSource(stream);
    const vadNode = new AudioWorkletNode(ctx, 'vad-processor');
    src.connect(vadNode);
    vadNode.port.onmessage = e => {
      if (e.data.speaking) onVoiceStart(); else onVoiceEnd();
    };
  } catch (err) {
    console.warn('ë§ˆì´í¬ ê¶Œí•œ/Worklet ë¡œë“œ ì‹¤íŒ¨:', err);
    transition(State.READY);
  }

  // SpeechRecognition fallback & interim
  recognition = new (window.SpeechRecognition||window.webkitSpeechRecognition)();
  recognition.continuous = true; recognition.interimResults = true; recognition.lang = 'ko-KR';
  recognition.onresult = e => {
    let interim='', final='';
    for(let i=e.resultIndex;i<e.results.length;i++){
      const t = e.results[i][0].transcript;
      e.results[i].isFinal ? final += t : interim += t;
    }
    if (interim) userBubble.textContent = interim;
    if (final) userBubble.textContent = final;
  };
  recognition.onspeechstart = onVoiceStart;
  recognition.onspeechend   = onVoiceEnd;
  recognition.onerror       = e => console.warn('SpeechRec ì˜¤ë¥˜', e);
})();

function onVoiceStart(){
  if (currentState === State.READY || currentState === State.SILENCE) {
    transition(State.RECORD);
    setMicStatus('ğŸ”´ ë“£ê³  ìˆì–´ìš”');
    userBubble = appendMessage('', 'user');
    if (recognition) recognition.start();
  }
}
function onVoiceEnd(){
  if (currentState === State.RECORD) {
    transition(State.SILENCE);
    setMicStatus('ğŸ”µ ëŒ€ê¸° ì¤‘');
    if (recognition) recognition.stop();
    silenceTimer = setTimeout(async()=>{
      // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ê°ì •íƒœê·¸ ë°˜ì˜
      const emo = localStorage.getItem('lozee_user_emotion_tag') || '';
      const sys = emo ? `ìœ ì € ê°ì •: ${emo}.` : '';
      await handleUserTurn(userBubble.textContent, sys);
      transition(State.READY);
    }, 20000);
  }
}

// ì‹œì‘: ì¸ë±ìŠ¤ì—ì„œ ì „ë‹¬ëœ ì¸íŠ¸ë¡œ ì²˜ë¦¬
window.addEventListener('DOMContentLoaded', async()=>{
  const intro = localStorage.getItem('lozee_user_typed_intro') || '';
  if (intro) {
    await handleUserTurn(intro);
    localStorage.removeItem('lozee_user_typed_intro');
  }
  transition(State.READY);
});
</script>
</body>
</html>
