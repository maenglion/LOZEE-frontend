<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LOZEE ëŒ€í™” (Streaming STT)</title>
  <link rel="stylesheet" href="style.css">
  <style>
    body { display:flex; flex-direction:column; min-height:100vh; margin:0; background:#fff; color:#333; font-family:'KoPubWorld Dotum',sans-serif; }
    #chat-window { flex:1; overflow-y:auto; padding:20px; display:flex; flex-direction:column; gap:12px; }
    .bubble { max-width:80%; padding:12px 18px; border-radius:20px; line-height:1.6; font-size:16px; white-space:pre-wrap; box-shadow:0 1px 3px rgba(0,0,0,0.1); }
    .user { background:#fff9c4; color:#333; align-self:flex-end; margin-left:auto; border-bottom-right-radius:5px; }
    .ai { background:#0095FF; color:#fff; align-self:flex-start; margin-right:auto; border-bottom-left-radius:5px; }
    #loading-indicator { text-align:center; padding:10px; display:none; color:#555; font-style:italic; }
    #talk-btn-container { text-align:center; padding:15px; border-top:1px solid #eee; background:#fafafa; }
    #talk-btn { width:80px; height:80px; border-radius:50%; background:#b6b6b6; border:none; box-shadow:0 4px 8px rgba(0,0,0,0.2); color:#fff; font-size:36px; cursor:pointer; transition:transform .2s,background-color .3s; }
    #talk-btn.recording { background:#e06c75; transform:scale(1.1); }
  </style>
</head>
<body>
  <div id="chat-window"></div>
  <div id="loading-indicator">ìŠ¤íŠ¸ë¦¬ë° ì¸ì‹ ì¤‘...</div>
  <div id="talk-btn-container">
    <button id="talk-btn" aria-label="ë§í•˜ê¸°">ğŸ¤</button>
  </div>

  <script type="module">
    import { playTTSFromText } from './js/tts.js';
    import { getGptResponse, getInitialGreeting } from './js/gpt-dialog.js';

    // WebSocket STT ì„œë²„ ì£¼ì†Œ
    const STT_WS_URL = 'wss://ggg-production.up.railway.app/api/sttStream';

    const chatWindow = document.getElementById('chat-window');
    const talkBtn = document.getElementById('talk-btn');
    const loading = document.getElementById('loading-indicator');

    let audioContext, micStream, processor;
    let ws;
    let isRecording = false;
    let firstDone = false;

    function appendMessage(text, role) {
      const div = document.createElement('div');
      div.className = `bubble ${role}`;
      div.textContent = text;
      chatWindow.appendChild(div);
      chatWindow.scrollTop = chatWindow.scrollHeight;
      return div;
    }

    function toggleLoading(state) {
      loading.style.display = state ? 'block' : 'none';
      talkBtn.disabled = state;
    }

    window.addEventListener('DOMContentLoaded', async () => {
      // ì´ˆê¸° ì¸ì‚¬
      const name = localStorage.getItem('lozee_username') || 'ì¹œêµ¬';
      const greeting = await getInitialGreeting(name);
      appendMessage(greeting, 'ai');

      talkBtn.addEventListener('click', async () => {
        if (!firstDone) {
          firstDone = true;
          toggleLoading(true);
          await playTTSFromText(greeting);
          toggleLoading(false);
          return;
        }
        isRecording ? stopStreamingSTT() : startStreamingSTT();
      });
    });

    async function startStreamingSTT() {
      // ì´ˆê¸°í™”
      isRecording = true;
      toggleLoading(true);
      appendMessage('â€¦', 'user');
      const userBubble = chatWindow.lastChild;

      // WebSocket ì—°ê²°
      ws = new WebSocket(STT_WS_URL);
      ws.binaryType = 'arraybuffer';
      ws.onopen = () => {
        loading.textContent = 'ìŠ¤íŠ¸ë¦¬ë° ì¸ì‹ ì¤‘...';
        loading.style.display = 'block';
      };
      ws.onmessage = async ({ data }) => {
        const msg = JSON.parse(data);
        if (msg.transcript) {
          userBubble.textContent = msg.transcript;
        }
        if (msg.isFinal) {
          // ìµœì¢… ì¸ì‹ ì™„ë£Œ
          ws.close();
          toggleLoading(false);
          await handleUserTurn(userBubble.textContent);
        }
      };
      ws.onerror = () => {
        toggleLoading(false);
        appendMessage('ìŒì„± ì¸ì‹ ì˜¤ë¥˜', 'ai');
      };

      // ì˜¤ë””ì˜¤ ìº¡ì²˜
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const source = audioContext.createMediaStreamSource(micStream);
      processor = audioContext.createScriptProcessor(4096, 1, 1);
      source.connect(processor);
      processor.connect(audioContext.destination);
      processor.onaudioprocess = e => {
        if (!isRecording) return;
        const input = e.inputBuffer.getChannelData(0);
        // 16-bit PCM ë³€í™˜
        const pcm = float32ToInt16(input);
        if (ws.readyState === WebSocket.OPEN) ws.send(pcm);
      };

      talkBtn.classList.add('recording');
    }

    function stopStreamingSTT() {
      isRecording = false;
      talkBtn.classList.remove('recording');
      processor.disconnect();
      micStream.getTracks().forEach(t => t.stop());
      audioContext.close();
      // ì›¹ì†Œì¼“ ë‹«í˜ì€ ì„œë²„ê°€ isFinal ì „ì†¡ í›„
    }

    function float32ToInt16(buffer) {
      const l = buffer.length;
      const buf = new Int16Array(l);
      for (let i = 0; i < l; i++) buf[i] = Math.min(1, buffer[i]) * 0x7FFF;
      return buf.buffer;
    }

    // GPT ì²˜ë¦¬
    async function handleUserTurn(text) {
      appendMessage(text, 'user');
      const res = await getGptResponse(text);
      const aiText = typeof res === 'string' ? res : (res.error || res.rephrasing || 'ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.');
      appendMessage(aiText, 'ai');
      await playTTSFromText(aiText);
    }
  </script>
</body>
</html>
