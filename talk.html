<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>LOZEEì™€ ëŒ€í™”í•˜ê¸°</title>
  <link rel="stylesheet" href="style.css" />
  <link href="https://fonts.googleapis.com/css2?family=KoPub+World+Dotum:wght@400;700&display=swap" rel="stylesheet" />
</head>
<body>
  <header id="main-header">LOZEEì™€ ëŒ€í™”í•˜ê¸°</header>
  <div id="meter-container"><div id="volume-meter"><div id="volume-level"></div></div></div>
  <div id="chat-container"></div>

  <div id="chat-input-container">
    <button id="mic-button" title="ìŒì„± ì¸ì‹ ì‹œì‘/ì¤‘ì§€" disabled>ğŸ¤</button>
    <input type="text" id="chat-input" placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”..." />
    <button id="send-button">ì „ì†¡</button>
  </div>

  <script type="module">
    import { playTTSFromText, DEFAULT_VOICE } from './js/tts.js';
    import { getGptResponse, getFirstQuestion } from './js/gpt-dialog.js';
    import { trackTime, trackEmotionTone, trackSituation } from './js/basic-features.js';

    document.addEventListener('DOMContentLoaded', () => {
      // --- ë³€ìˆ˜ ë° ìš”ì†Œ ì°¸ì¡° ---
      const chatContainer = document.getElementById('chat-container');
      const chatInput     = document.getElementById('chat-input');
      const sendButton    = document.getElementById('send-button');
      const micButton     = document.getElementById('mic-button');
      const meterLevel    = document.getElementById('volume-level');

      const selectedVoice = localStorage.getItem('lozee_selectedVoice') || DEFAULT_VOICE;
      const userAge       = localStorage.getItem('lozee_userage');
      const userName      = localStorage.getItem('lozee_username') || 'ì¹œêµ¬';
      const storedTopic   = localStorage.getItem('selectedTopic') || '{}';
      const selectedTopic = JSON.parse(storedTopic);

      let recognitionActive = false;
      let stt;

      // --- í—¬í¼ í•¨ìˆ˜ë“¤ ---
      function appendBubble(text, role) {
        const el = document.createElement('div');
        el.className = `bubble ${role}`;
        el.textContent = text;
        chatContainer.appendChild(el);
        chatContainer.scrollTop = chatContainer.scrollHeight;
      }

      function showAiLoading(show) {
        sendButton.disabled = show;
        chatInput.disabled  = show;
        micButton.disabled  = show || micButton.disabled;
      }

      async function initConversation() {
        console.log('â–¶ï¸ selectedTopic:', selectedTopic);
        console.log('â–¶ï¸ initConversation ì‹œì‘');
        const prompt = getFirstQuestion(userAge, selectedTopic);
        appendBubble(prompt, 'bot');
        await playTTSFromText(prompt, selectedVoice);
        trackTime();
        trackEmotionTone();
        trackSituation();
      }

      async function handleUserText(text) {
        if (!text.trim()) return;
        appendBubble(text, 'user');
        showAiLoading(true);

        const botBubble = document.createElement('div');
        botBubble.className = 'bubble bot';
        chatContainer.appendChild(botBubble);

        try {
          const res = await getGptResponse(text, { userAge, userName, selectedTopic });
          const reader = res.body.getReader();
          const dec = new TextDecoder();
          let done = false;
          while (!done) {
            const { value, done: d } = await reader.read();
            done = d;
            botBubble.textContent += dec.decode(value, { stream: true });
            chatContainer.scrollTop = chatContainer.scrollHeight;
          }
          await playTTSFromText(botBubble.textContent, selectedVoice);
        } catch (err) {
          console.error('GPT streaming error', err);
          appendBubble('ì£„ì†¡í•´ìš”, ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.', 'bot');
          await playTTSFromText('ì£„ì†¡í•´ìš”, ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.', selectedVoice);
        } finally {
          showAiLoading(false);
        }
      }

      // --- ì´ë²¤íŠ¸ ë°”ì¸ë”© ---
      sendButton.addEventListener('click', () => {
        const txt = chatInput.value.trim();
        if (txt) { chatInput.value = ''; handleUserText(txt); }
      });
      chatInput.addEventListener('keydown', e => {
        if (e.key === 'Enter' && !sendButton.disabled) {
          e.preventDefault();
          const txt = chatInput.value.trim();
          if (txt) { chatInput.value = ''; handleUserText(txt); }
        }
      });

      // --- STT ì„¤ì • ---
      if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
        navigator.mediaDevices.getUserMedia({ audio: true })
          .then(() => {
            const API = window.SpeechRecognition || window.webkitSpeechRecognition;
            stt = new API();
            stt.lang = 'ko-KR'; stt.interimResults = false;
            stt.onstart = () => { recognitionActive = true; micButton.textContent = 'ğŸ”´'; };
            stt.onend   = () => { recognitionActive = false; micButton.textContent = 'ğŸ¤'; };
            stt.onresult = e => { handleUserText(e.results[0][0].transcript); };
            micButton.disabled = false;
            micButton.onclick = () => recognitionActive ? stt.stop() : stt.start();
          })
          .catch(err => {
            console.error('Microphone permission denied', err);
            appendBubble('ë§ˆì´í¬ ê¶Œí•œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ìš”.', 'bot');
          });
      } else {
        console.error('Web Speech API not supported');
        appendBubble('ìŒì„± ì¸ì‹ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ìš”.', 'bot');
      }

      // --- ëŒ€í™” ì‹œì‘ ---
      initConversation();
    });
  </script>
</body>
</html>
