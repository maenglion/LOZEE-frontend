<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LOZEE ëŒ€í™” (Streaming STT)</title>
  <link rel="stylesheet" href="style.css">
  <style>
    body { display:flex; flex-direction:column; min-height:100vh; margin:0; background:#fff; color:#333; font-family:'KoPubWorld Dotum',sans-serif; }
    #main-header { background:#0095FF; color:#fff; padding:1rem; text-align:center; font-size:20px; }
    #voice-selector { margin:10px; text-align:center; }
    #chat-window { flex:1; overflow-y:auto; padding:20px; display:flex; flex-direction:column; gap:12px; }
    .bubble { max-width:80%; padding:12px 18px; border-radius:20px; line-height:1.6; font-size:16px; white-space:pre-wrap; box-shadow:0 1px 3px rgba(0,0,0,0.1); }
    .user { background:#fff9c4; color:#333; align-self:flex-end; margin-left:auto; border-bottom-right-radius:5px; }
    .ai { background:#0095FF; color:#fff; align-self:flex-start; margin-right:auto; border-bottom-left-radius:5px; }
    #loading-indicator { text-align:center; padding:10px; display:none; color:#555; font-style:italic; }
    #talk-btn-container { text-align:center; padding:15px; border-top:1px solid #eee; background:#fafafa; }
    #talk-btn { width:80px; height:80px; border-radius:50%; background:#b6b6b6; border:none; box-shadow:0 4px 8px rgba(0,0,0,0.2); color:#fff; font-size:36px; cursor:pointer; transition:transform .2s,background-color .3s; }
    #talk-btn.recording { background:#e06c75; transform:scale(1.1); }
  </style>
</head>
<body>
  <header id="main-header">LOZEE ëŒ€í™”</header>
  <div id="voice-selector">
    <label for="tts-voice">ìŒì„± ì„ íƒ: </label>
    <select id="tts-voice">
      <option value="ko-KR-Chirp3-HD-Vindemiatrix">ì—¬ì„±/ë‚®ì€í†¤/ë§ ë¹ ë¦„</option>
      <option value="ko-KR-Chirp3-HD-Rasalgethi">ë‚¨ì„±/ë†’ì€í†¤/ë§ ëŠë¦¼</option>
      <option value="ko-KR-Chirp3-HD-Leda">ì—¬ì„±/ë†’ì€í†¤/ë§ ë¹ ë¦„</option>
      <option value="ko-KR-Chirp3-HD-Sadachbia">ë‚¨ì„±/ë†’ì€í†¤/ë³´í†µ</option>
      <option value="ko-KR-Chirp3-HD-Kore">ì—¬ì„±/ì¤‘ê°„í†¤/ë§ ë¹ ë¦„</option>
      <option value="ko-KR-Chirp3-HD-Schedar">ë‚¨ì„±/ë†’ì€í†¤/ë¹ ë¦„</option>
    </select>
  </div>
  <div id="chat-window"></div>
  <div id="loading-indicator">ìŠ¤íŠ¸ë¦¬ë° ì¸ì‹ ì¤‘...</div>
  <div id="talk-btn-container">
    <button id="talk-btn" aria-label="ë§í•˜ê¸°">ğŸ¤</button>
  </div>

  <script type="module">
    import { playTTSFromText } from './js/tts.js';
    import { getGptResponse, getInitialGreeting } from './js/gpt-dialog.js';
    import { getSTTFromAudio } from './js/stt.js';

    const STT_WS_URL = 'wss://ggg-production.up.railway.app/api/sttStream';
    const voiceSelect = document.getElementById('tts-voice');
    const chatWindow  = document.getElementById('chat-window');
    const talkBtn     = document.getElementById('talk-btn');
    const loading     = document.getElementById('loading-indicator');

        // TTS ìŒì„± ID (indexì—ì„œ ì„¤ì •ëœ ê°’ ì‚¬ìš©)
    const ttsVoiceId = localStorage.getItem('lozee_tts_voice') || 'ko-KR-Chirp3-HD-Vindemiatrix';
    function currentVoice() { return ttsVoiceId; }
function appendMessage(text, role) {
      const div = document.createElement('div'); div.className = `bubble ${role}`; div.textContent = text;
      chatWindow.appendChild(div); chatWindow.scrollTop = chatWindow.scrollHeight; return div;
    }
    function toggleLoading(state) {
      loading.style.display = state ? 'block' : 'none'; talkBtn.disabled = state;
    }

    let audioContext, micStream, processor, ws;
    let isRecording = false, firstDone = false;

    window.addEventListener('DOMContentLoaded', async () => {
      const name = localStorage.getItem('lozee_username') || 'ì¹œêµ¬';
      const greeting = await getInitialGreeting(name);
      appendMessage(greeting, 'ai');

      talkBtn.addEventListener('click', async () => {
        if (!firstDone) {
          firstDone = true; toggleLoading(true);
          await playTTSFromText(greeting, currentVoice());
          toggleLoading(false); return;
        }
        isRecording ? stopStreamingSTT() : startStreamingSTT();
      });
    });

    async function startStreamingSTT() {
      isRecording = true; toggleLoading(true);
      appendMessage('â€¦', 'user'); const userBubble = chatWindow.lastChild;

      ws = new WebSocket(STT_WS_URL); ws.binaryType = 'arraybuffer';
      ws.onopen = () => { loading.textContent = 'ìŠ¤íŠ¸ë¦¬ë° ì¸ì‹ ì¤‘...'; loading.style.display = 'block'; };
      ws.onmessage = async ({ data }) => {
        const msg = JSON.parse(data);
        if (msg.transcript) userBubble.textContent = msg.transcript;
        if (msg.isFinal) { ws.close(); toggleLoading(false); await handleUserTurn(userBubble.textContent); }
      };
      ws.onerror = () => { toggleLoading(false); appendMessage('ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜, í´ë°± ëª¨ë“œ', 'ai'); stopStreamingSTT(); startChunkedSTT(); };

      audioContext = new (window.AudioContext||window.webkitAudioContext)();
      micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const src = audioContext.createMediaStreamSource(micStream);
      processor = audioContext.createScriptProcessor(4096,1,1);
      src.connect(processor); processor.connect(audioContext.destination);
      processor.onaudioprocess = e => {
        if (!isRecording) return;
        const data = e.inputBuffer.getChannelData(0);
        const pcm = float32ToInt16(data);
        if (ws.readyState===WebSocket.OPEN) ws.send(pcm);
      };

      talkBtn.classList.add('recording');
    }

    function stopStreamingSTT() {
      isRecording = false; talkBtn.classList.remove('recording');
      processor.disconnect(); micStream.getTracks().forEach(t=>t.stop()); audioContext.close();
    }

    function float32ToInt16(buffer) {
      const l=buffer.length,buf=new Int16Array(l);
      for(let i=0;i<l;i++)buf[i]=Math.min(1,buffer[i])*0x7FFF;
      return buf.buffer;
    }

    async function handleUserTurn(text) {
      appendMessage(text,'user');
      const res = await getGptResponse(text);
      const out = typeof res==='string'?res:(res.error||res.rephrasing||'ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.');
      appendMessage(out,'ai'); await playTTSFromText(out,currentVoice());
    }

    async function startChunkedSTT() {
      appendMessage('í´ë°± STT ëª¨ë“œë¡œ ì „í™˜','ai');
      try{ processor.disconnect(); audioContext.close(); micStream.getTracks().forEach(t=>t.stop()); }catch{}
      const stream=await navigator.mediaDevices.getUserMedia({audio:true});
      const rec=new MediaRecorder(stream);let chunks=[];
      rec.ondataavailable=e=>chunks.push(e.data);
      rec.onstop=async()=>{const blob=new Blob(chunks,{type:'audio/webm'});chunks=[];
        try{const txt=await getSTTFromAudio(blob);await handleUserTurn(txt);}catch{appendMessage('ì²­í¬ STT ì˜¤ë¥˜','ai');}}
      ;rec.start();appendMessage('5ì´ˆ í›„ ì²­í¬ ì „ì†¡','ai');setTimeout(()=>rec.stop(),5000);
    }
  </script>
</body>
</html>
